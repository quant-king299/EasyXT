# -*- coding: utf-8 -*-
"""
å¤šæ•°æ®æºæ•°æ®ç®¡ç†å™¨
è´Ÿè´£è·å–ã€æ¸…æ´—å’Œè½¬æ¢å›æµ‹æ‰€éœ€çš„å†å²æ•°æ®
æ”¯æŒå¤šæ•°æ®æºï¼šQMT â†’ QStock â†’ AKShare â†’ æ¨¡æ‹Ÿæ•°æ®
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Union
import warnings
from enum import Enum

class DataSource(Enum):
    """æ•°æ®æºæšä¸¾"""
    DUCKDB = "duckdb"  # DuckDBæœ¬åœ°æ•°æ®åº“ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼Œæ€§èƒ½æœ€ä¼˜ï¼‰
    LOCAL = "local"    # æœ¬åœ°ç¼“å­˜ï¼ˆParquetï¼‰
    QMT = "qmt"        # QMTå®æ—¶æ•°æ®
    QSTOCK = "qstock"  # QStockæ•°æ®
    AKSHARE = "akshare" # AKShareæ•°æ®
    MOCK = "mock"      # æ¨¡æ‹Ÿæ•°æ®

class DataManager:
    """
    å¤šæ•°æ®æºæ•°æ®ç®¡ç†å™¨
    
    åŠŸèƒ½ç‰¹æ€§ï¼š
    1. å¤šæ•°æ®æºæ”¯æŒï¼šQMT â†’ QStock â†’ AKShare â†’ æ¨¡æ‹Ÿæ•°æ®
    2. è‡ªåŠ¨æ•°æ®æºåˆ‡æ¢å’Œæ‰‹åŠ¨æŒ‡å®š
    3. æ•°æ®æ¸…æ´—å’Œè´¨é‡æ£€æŸ¥
    4. æ ¼å¼è½¬æ¢å’Œæ ‡å‡†åŒ–
    5. æ•°æ®æºçŠ¶æ€ç›‘æ§
    """
    
    def __init__(self, preferred_source: Optional[DataSource] = None,
                 use_local_cache: bool = True):
        """
        åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨

        Args:
            preferred_source: é¦–é€‰æ•°æ®æºï¼ŒNoneè¡¨ç¤ºè‡ªåŠ¨é€‰æ‹©
            use_local_cache: æ˜¯å¦ä½¿ç”¨æœ¬åœ°ç¼“å­˜
        """
        self.preferred_source = preferred_source
        self.use_local_cache = use_local_cache

        # åˆå§‹åŒ–DuckDBæ•°æ®åº“ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        self.duckdb_connection = None
        self.duckdb_path = 'D:/StockData/stock_data.ddb'
        self._duckdb_enabled = False  # æ ‡è®°DuckDBæ˜¯å¦å¯ç”¨
        try:
            import duckdb
            # å»¶è¿Ÿè¿æ¥ï¼Œä¸åœ¨åˆå§‹åŒ–æ—¶æ‰“å¼€
            self._duckdb_enabled = True
            print("[OK] DuckDBæ•°æ®åº“å·²å¯ç”¨ (åªè¯»æ¨¡å¼)")
        except ImportError:
            print("[INFO] DuckDBæœªå®‰è£…ï¼Œè·³è¿‡DuckDBæ•°æ®æº")
        except Exception as e:
            print(f"[WARNING] DuckDBåˆå§‹åŒ–å¤±è´¥: {e}")

        # æœ¬åœ°æ•°æ®ç®¡ç†å™¨ï¼ˆParquetç¼“å­˜ï¼‰å·²å¼ƒç”¨ - æ‰€æœ‰æ•°æ®ä½¿ç”¨DuckDB
        self.local_data_manager = None
        # æ³¨é‡Šï¼šæ—§ç‰ˆæœ¬ä½¿ç”¨Parquetæ–‡ä»¶ä½œä¸ºç¼“å­˜ï¼Œç°å·²å…¨éƒ¨è¿ç§»åˆ°DuckDB

        # æ£€æŸ¥å„æ•°æ®æºå¯ç”¨æ€§
        self.source_status = self._check_all_sources()

        # ç¡®å®šæ•°æ®æºä¼˜å…ˆçº§
        self.source_priority = self._get_source_priority()

        # æ˜¾ç¤ºåˆå§‹åŒ–çŠ¶æ€
        self._print_initialization_status()
        
    def _check_all_sources(self) -> Dict[DataSource, Dict[str, any]]:
        """æ£€æŸ¥æ‰€æœ‰æ•°æ®æºçš„å¯ç”¨æ€§"""
        status = {}

        # æ£€æŸ¥DuckDBæ•°æ®åº“
        status[DataSource.DUCKDB] = self._check_duckdb_status()

        # æ£€æŸ¥æœ¬åœ°ç¼“å­˜ï¼ˆParquetï¼‰
        status[DataSource.LOCAL] = self._check_local_status()

        # æ£€æŸ¥QMT
        status[DataSource.QMT] = self._check_qmt_status()

        # æ£€æŸ¥QStock
        status[DataSource.QSTOCK] = self._check_qstock_status()

        # æ£€æŸ¥AKShare
        status[DataSource.AKSHARE] = self._check_akshare_status()

        # æ¨¡æ‹Ÿæ•°æ®æ€»æ˜¯å¯ç”¨
        status[DataSource.MOCK] = {
            'available': True,
            'connected': True,
            'message': 'æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå™¨'
        }

        return status

    def _check_duckdb_status(self) -> Dict[str, any]:
        """æ£€æŸ¥DuckDBæ•°æ®åº“çŠ¶æ€"""
        if self.duckdb_connection is not None:
            try:
                # æµ‹è¯•æŸ¥è¯¢
                result = self.duckdb_connection.execute("""
                    SELECT COUNT(*) as count FROM stock_daily LIMIT 1
                """).fetchone()

                if result and result[0] > 0:
                    return {
                        'available': True,
                        'connected': True,
                        'message': f'DuckDBæ•°æ®åº“ ({result[0]:,}æ¡è®°å½•)'
                    }
                else:
                    return {
                        'available': True,
                        'connected': False,
                        'message': 'DuckDBæ•°æ®åº“ä¸ºç©º'
                    }
            except Exception as e:
                return {
                    'available': False,
                    'connected': False,
                    'message': f'DuckDBæŸ¥è¯¢å¤±è´¥: {str(e)[:50]}'
                }
        return {
            'available': False,
            'connected': False,
            'message': 'DuckDBæœªè¿æ¥'
        }

    def _check_local_status(self) -> Dict[str, any]:
        """æ£€æŸ¥æœ¬åœ°ç¼“å­˜çŠ¶æ€"""
        if self.local_data_manager is not None:
            stats = self.local_data_manager.get_statistics()
            total_symbols = stats.get('total_symbols', 0)
            return {
                'available': True,
                'connected': total_symbols > 0,
                'message': f'æœ¬åœ°ç¼“å­˜ ({total_symbols}ä¸ªæ ‡çš„)'
            }
        return {
            'available': False,
            'connected': False,
            'message': 'æœ¬åœ°ç¼“å­˜æœªå¯ç”¨'
        }
        
    def _check_qmt_status(self) -> Dict[str, any]:
        """æ£€æŸ¥QMTçŠ¶æ€"""
        try:
            import xtquant.xtdata as xt_data
            
            # å¿«é€Ÿè¿æ¥æ£€æµ‹
            import threading
            result = {'connected': False}
            
            def quick_check():
                try:
                    info = xt_data.get_instrument_detail('000001.SZ')
                    if info and len(info) > 0:
                        result['connected'] = True
                except:
                    result['connected'] = False
            
            check_thread = threading.Thread(target=quick_check)
            check_thread.daemon = True
            check_thread.start()
            check_thread.join(timeout=5.0)  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°5ç§’
            
            return {
                'available': True,
                'connected': result['connected'],
                'message': 'QMTå·²è¿æ¥' if result['connected'] else 'QMTæœªè¿æ¥'
            }
            
        except ImportError:
            return {
                'available': False,
                'connected': False,
                'message': 'xtquantæ¨¡å—æœªå®‰è£…'
            }
        except Exception as e:
            return {
                'available': True,
                'connected': False,
                'message': f'QMTè¿æ¥æ£€æµ‹å¤±è´¥: {str(e)}'
            }
    
    def _check_qstock_status(self) -> Dict[str, any]:
        """æ£€æŸ¥QStockçŠ¶æ€"""
        try:
            import qstock as qs
            
            # å°è¯•è·å–ä¸€ä¸ªç®€å•çš„æ•°æ®æ¥æµ‹è¯•è¿æ¥
            try:
                # æµ‹è¯•è·å–è‚¡ç¥¨åˆ—è¡¨ï¼ˆè¿™ä¸ªæ“ä½œé€šå¸¸æ¯”è¾ƒå¿«ï¼‰
                test_data = qs.get_data('000001', start='2024-01-01', end='2024-01-02')
                if test_data is not None and not test_data.empty:
                    return {
                        'available': True,
                        'connected': True,
                        'message': 'QStockè¿æ¥æ­£å¸¸'
                    }
                else:
                    return {
                        'available': True,
                        'connected': False,
                        'message': 'QStockæ— æ³•è·å–æ•°æ®'
                    }
            except Exception as e:
                return {
                    'available': True,
                    'connected': False,
                    'message': f'QStockè¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}'
                }
                
        except ImportError:
            return {
                'available': False,
                'connected': False,
                'message': 'qstockæ¨¡å—æœªå®‰è£…'
            }
    
    def _check_akshare_status(self) -> Dict[str, any]:
        """æ£€æŸ¥AKShareçŠ¶æ€ - ä¼˜åŒ–ç‰ˆæœ¬"""
        try:
            import akshare as ak
            
            # AKShareæ¨¡å—å·²å®‰è£…ï¼Œæ ‡è®°ä¸ºå¯ç”¨
            # ä¸è¿›è¡Œå®æ—¶è¿æ¥æµ‹è¯•ï¼Œé¿å…ç½‘ç»œé—®é¢˜å½±å“å¯åŠ¨
            try:
                # å°è¯•ä¸€ä¸ªè½»é‡çº§çš„æµ‹è¯•ï¼Œå¦‚æœå¤±è´¥ä¹Ÿä¸å½±å“å¯ç”¨æ€§
                # åªæ˜¯ç®€å•æ£€æŸ¥æ¨¡å—æ˜¯å¦æ­£å¸¸å¯¼å…¥
                version = getattr(ak, '__version__', 'unknown')
                
                return {
                    'available': True,
                    'connected': True,  # å‡è®¾è¿æ¥æ­£å¸¸ï¼Œå®é™…ä½¿ç”¨æ—¶å†å¤„ç†é”™è¯¯
                    'message': f'AKShareæ¨¡å—å·²å®‰è£… (v{version})'
                }
                
            except Exception as e:
                # å³ä½¿æµ‹è¯•å¤±è´¥ï¼Œä¹Ÿæ ‡è®°ä¸ºå¯ç”¨ï¼Œå› ä¸ºæ¨¡å—å·²å®‰è£…
                return {
                    'available': True,
                    'connected': True,  # ä¹è§‚å‡è®¾ï¼Œå®é™…ä½¿ç”¨æ—¶å¤„ç†é”™è¯¯
                    'message': f'AKShareæ¨¡å—å·²å®‰è£…ï¼Œè¿æ¥çŠ¶æ€æœªçŸ¥'
                }
                
        except ImportError:
            return {
                'available': False,
                'connected': False,
                'message': 'akshareæ¨¡å—æœªå®‰è£…'
            }
    
    def _get_source_priority(self) -> List[DataSource]:
        """è·å–æ•°æ®æºä¼˜å…ˆçº§åˆ—è¡¨"""
        if self.preferred_source:
            # å¦‚æœæŒ‡å®šäº†é¦–é€‰æ•°æ®æºï¼Œå°†å…¶æ”¾åœ¨é¦–ä½
            priority = [self.preferred_source]
            other_sources = [s for s in DataSource if s != self.preferred_source]
            priority.extend(other_sources)
            return priority
        else:
            # é»˜è®¤ä¼˜å…ˆçº§ï¼šDuckDB â†’ QMT â†’ LOCAL â†’ QStock â†’ AKShare â†’ MOCK
            # DuckDBä¼˜å…ˆï¼Œå› ä¸ºå®ƒæ€§èƒ½æœ€ä¼˜ä¸”å·²è¿ç§»å¤§é‡æ•°æ®
            priority = [DataSource.QMT, DataSource.QSTOCK, DataSource.AKSHARE, DataSource.MOCK]

            # å¦‚æœDuckDBå¯ç”¨ï¼Œæ”¾åœ¨ç¬¬ä¸€ä½ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
            if (self.duckdb_connection is not None and
                self.source_status[DataSource.DUCKDB]['connected']):
                priority.insert(0, DataSource.DUCKDB)

            # å¦‚æœæœ¬åœ°ç¼“å­˜å¯ç”¨ï¼Œæ”¾åœ¨ç¬¬äºŒä½
            if (self.local_data_manager is not None and
                self.source_status[DataSource.LOCAL]['connected']):
                if DataSource.DUCKDB in priority:
                    # DuckDBå·²å­˜åœ¨ï¼Œæ’å…¥åˆ°DuckDBä¹‹å
                    duckdb_idx = priority.index(DataSource.DUCKDB)
                    priority.insert(duckdb_idx + 1, DataSource.LOCAL)
                else:
                    # æ²¡æœ‰DuckDBï¼Œæ’å…¥åˆ°ç¬¬ä¸€ä½
                    priority.insert(0, DataSource.LOCAL)

            return priority
    
    def _print_initialization_status(self):
        """æ‰“å°åˆå§‹åŒ–çŠ¶æ€"""
        print("[DATA] å¤šæ•°æ®æºç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        print("=" * 50)
        
        for source in DataSource:
            status = self.source_status[source]
            if status['available']:
                if status['connected']:
                    icon = "[OK]"
                    color_status = "å·²è¿æ¥"
                else:
                    icon = "[WARNING]"
                    color_status = "æœªè¿æ¥"
            else:
                icon = "[ERROR]"
                color_status = "ä¸å¯ç”¨"

            print(f"   {icon} {source.value.upper():<8}: {color_status} - {status['message']}")
        
        print("=" * 50)
        
        # æ˜¾ç¤ºå½“å‰å¯ç”¨çš„æ•°æ®æº
        available_sources = [s.value.upper() for s in self.source_priority 
                           if self.source_status[s]['available'] and self.source_status[s]['connected']]
        
        if available_sources:
            print(f"[TARGET] å¯ç”¨æ•°æ®æº: {' â†’ '.join(available_sources)}")
        else:
            print("[INFO] ä»…æ¨¡æ‹Ÿæ•°æ®å¯ç”¨")
        
        print("=" * 50)
    
    def get_connection_status(self) -> Dict[str, any]:
        """è·å–è¿æ¥çŠ¶æ€ä¿¡æ¯"""
        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¯ç”¨ä¸”å·²è¿æ¥çš„æ•°æ®æº
        active_source = None
        for source in self.source_priority:
            if (self.source_status[source]['available'] and 
                self.source_status[source]['connected']):
                active_source = source
                break
        
        if not active_source:
            active_source = DataSource.MOCK
        
        return {
            'active_source': active_source.value,
            'source_status': {s.value: status for s, status in self.source_status.items()},
            'qmt_connected': self.source_status[DataSource.QMT]['connected'],
            'xt_available': self.source_status[DataSource.QMT]['available'],
            'data_source': 'real' if active_source != DataSource.MOCK else 'mock',
            'status_message': self._get_status_message(active_source)
        }
    
    def _get_status_message(self, active_source: DataSource) -> str:
        """è·å–çŠ¶æ€æ¶ˆæ¯"""
        if active_source == DataSource.DUCKDB:
            return "[OK] ä½¿ç”¨DuckDBæ•°æ®åº“ï¼Œé«˜é€Ÿè¯»å–æœ¬åœ°çœŸå®æ•°æ®"
        elif active_source == DataSource.LOCAL:
            return "[OK] ä½¿ç”¨æœ¬åœ°ç¼“å­˜æ•°æ®ï¼ˆçœŸå®å†å²æ•°æ®ï¼‰"
        elif active_source == DataSource.QMT:
            return "[OK] å·²è¿æ¥åˆ°QMTï¼Œä½¿ç”¨çœŸå®å¸‚åœºæ•°æ®"
        elif active_source == DataSource.QSTOCK:
            return "[OK] å·²è¿æ¥åˆ°QStockï¼Œä½¿ç”¨çœŸå®å¸‚åœºæ•°æ®"
        elif active_source == DataSource.AKSHARE:
            return "[OK] å·²è¿æ¥åˆ°AKShareï¼Œä½¿ç”¨çœŸå®å¸‚åœºæ•°æ®"
        else:
            return "[INFO] ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®"
    
    def set_preferred_source(self, source: DataSource):
        """è®¾ç½®é¦–é€‰æ•°æ®æº"""
        self.preferred_source = source
        self.source_priority = self._get_source_priority()
        print(f"[INFO] é¦–é€‰æ•°æ®æºå·²è®¾ç½®ä¸º: {source.value.upper()}")
    
    def refresh_source_status(self):
        """åˆ·æ–°æ‰€æœ‰æ•°æ®æºçŠ¶æ€"""
        print("[RELOAD] åˆ·æ–°æ•°æ®æºçŠ¶æ€...")
        self.source_status = self._check_all_sources()
        self._print_initialization_status()
    
    def get_stock_data(self,
                      stock_code: str,
                      start_date: str,
                      end_date: str,
                      period: str = '1d',
                      force_source: Optional[DataSource] = None,
                      adjust: str = 'none') -> pd.DataFrame:
        """
        è·å–è‚¡ç¥¨å†å²æ•°æ®ï¼ˆæ”¯æŒå¤šæ•°æ®æº + å¤æƒï¼‰

        Args:
            stock_code: è‚¡ç¥¨ä»£ç  (å¦‚ '000001.SZ')
            start_date: å¼€å§‹æ—¥æœŸ ('YYYY-MM-DD')
            end_date: ç»“æŸæ—¥æœŸ ('YYYY-MM-DD')
            period: æ•°æ®å‘¨æœŸ ('1d', '1h', '5m' ç­‰)
            force_source: å¼ºåˆ¶ä½¿ç”¨æŒ‡å®šæ•°æ®æº
            adjust: å¤æƒç±»å‹ ('none'=ä¸å¤æƒ, 'front'=å‰å¤æƒ, 'back'=åå¤æƒ)

        Returns:
            åŒ…å«OHLCVæ•°æ®çš„DataFrameï¼ˆå·²åº”ç”¨å¤æƒï¼‰
        """
        adjust_types = {'none': 'ä¸å¤æƒ', 'front': 'å‰å¤æƒ', 'back': 'åå¤æƒ'}
        print(f"[DATA] è·å–è‚¡ç¥¨æ•°æ®: {stock_code} ({start_date} ~ {end_date})")
        print(f"   å¤æƒç±»å‹: {adjust_types.get(adjust, adjust)}")

        # å¦‚æœå¼ºåˆ¶æŒ‡å®šæ•°æ®æº
        if force_source:
            print(f"[TARGET] å¼ºåˆ¶ä½¿ç”¨æ•°æ®æº: {force_source.value.upper()}")
            return self._get_data_from_source(force_source, stock_code, start_date, end_date, period, adjust)

        # æŒ‰ä¼˜å…ˆçº§å°è¯•å„ä¸ªæ•°æ®æº
        downloaded_from = None  # è®°å½•ä»å“ªä¸ªæ•°æ®æºä¸‹è½½

        for source in self.source_priority:
            if (self.source_status[source]['available'] and
                self.source_status[source]['connected']):

                print(f"[LINK] å°è¯•æ•°æ®æº: {source.value.upper()}")

                try:
                    data = self._get_data_from_source(source, stock_code, start_date, end_date, period, adjust)
                    if not data.empty:
                        print(f"[OK] æˆåŠŸä» {source.value.upper()} è·å–æ•°æ®")

                        # å¦‚æœä¸æ˜¯ä»æœ¬åœ°ç¼“å­˜è·å–ï¼Œä¸”å¯ç”¨äº†æœ¬åœ°ç¼“å­˜ï¼Œåˆ™ä¿å­˜åˆ°æœ¬åœ°
                        if source != DataSource.LOCAL and self.local_data_manager is not None:
                            self._save_to_local_cache(stock_code, data)
                            downloaded_from = source.value

                        return data
                    else:
                        print(f"[WARNING] {source.value.upper()} è¿”å›ç©ºæ•°æ®ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ•°æ®æº")

                except Exception as e:
                    print(f"[WARNING] {source.value.upper()} è·å–æ•°æ®å¤±è´¥: {e}ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ•°æ®æº")
                    continue

        # å¦‚æœæ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
        print("[INFO] æ‰€æœ‰æ•°æ®æºå¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
        return self._get_data_from_source(DataSource.MOCK, stock_code, start_date, end_date, period, adjust)

    def _save_to_local_cache(self, stock_code: str, data: pd.DataFrame):
        """ä¿å­˜æ•°æ®åˆ°æœ¬åœ°ç¼“å­˜"""
        try:
            # ç¡®ä¿æ—¥æœŸç´¢å¼•
            if not isinstance(data.index, pd.DatetimeIndex):
                if 'date' in data.columns:
                    data = data.set_index('date')
                data.index = pd.to_datetime(data.index)

            # ä¿å­˜åˆ°æœ¬åœ°
            success, file_size = self.local_data_manager.storage.save_data(
                data, stock_code, 'daily'
            )

            if success:
                # æ›´æ–°å…ƒæ•°æ®
                self.local_data_manager.metadata.update_data_version(
                    symbol=stock_code,
                    symbol_type='stock',
                    start_date=str(data.index.min().date()),
                    end_date=str(data.index.max().date()),
                    record_count=len(data),
                    file_size=file_size
                )
                print(f"[SAVE] æ•°æ®å·²ç¼“å­˜åˆ°æœ¬åœ°")
        except Exception as e:
            print(f"[WARNING] ä¿å­˜åˆ°æœ¬åœ°ç¼“å­˜å¤±è´¥: {e}")
    
    def _get_data_from_source(self, source: DataSource, stock_code: str,
                            start_date: str, end_date: str, period: str, adjust: str = 'none') -> pd.DataFrame:
        """ä»æŒ‡å®šæ•°æ®æºè·å–æ•°æ®ï¼ˆæ”¯æŒå¤æƒï¼‰"""
        if source == DataSource.DUCKDB:
            return self._get_duckdb_data(stock_code, start_date, end_date, adjust)
        elif source == DataSource.LOCAL:
            return self._get_local_data(stock_code, start_date, end_date, adjust)
        elif source == DataSource.QMT:
            return self._get_qmt_data(stock_code, start_date, end_date, period, adjust)
        elif source == DataSource.QSTOCK:
            return self._get_qstock_data(stock_code, start_date, end_date, period)
        elif source == DataSource.AKSHARE:
            return self._get_akshare_data(stock_code, start_date, end_date, period)
        else:  # DataSource.MOCK
            return self._generate_mock_data(stock_code, start_date, end_date)

    def _get_duckdb_data(self, stock_code: str, start_date: str, end_date: str, adjust: str = 'none') -> pd.DataFrame:
        """ä»DuckDBæ•°æ®åº“è·å–æ•°æ®ï¼ˆé«˜æ€§èƒ½ï¼‰"""
        try:
            if not self._duckdb_enabled:
                return pd.DataFrame()

            import duckdb

            # æŒ‰éœ€æ‰“å¼€è¿æ¥ï¼Œä½¿ç”¨åç«‹å³å…³é—­
            con = duckdb.connect(self.duckdb_path, read_only=True)
            try:
                # æ„å»ºSQLæŸ¥è¯¢
                query = f"""
                    SELECT date, open, high, low, close, volume, amount
                    FROM stock_daily
                    WHERE stock_code = '{stock_code}'
                      AND date >= '{start_date}'
                      AND date <= '{end_date}'
                    ORDER BY date
                """

                # æ‰§è¡ŒæŸ¥è¯¢
                df = con.execute(query).df()

                if df.empty:
                    return pd.DataFrame()

                # ç¡®ä¿æ—¥æœŸç´¢å¼•
                if 'date' in df.columns:
                    df = df.set_index('date')
                    df.index = pd.to_datetime(df.index)

                # æ•°æ®æ¸…æ´—
                df = self._standardize_columns(df)
                df = self._clean_data(df)

                print(f"[OK] DuckDBè·å– {len(df)} æ¡æ•°æ®")

                return df

            finally:
                # ç«‹å³å…³é—­è¿æ¥
                con.close()

        except Exception as e:
            print(f"[ERROR] DuckDBæŸ¥è¯¢å¤±è´¥: {e}")
            return pd.DataFrame()

        except Exception as e:
            print(f"[WARNING] DuckDBè·å–æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()

    def _get_local_data(self, stock_code: str, start_date: str, end_date: str, adjust: str = 'none') -> pd.DataFrame:
        """ä»æœ¬åœ°ç¼“å­˜è·å–æ•°æ®ï¼ˆæ”¯æŒå¤æƒï¼‰"""
        try:
            if self.local_data_manager is None:
                return pd.DataFrame()

            # å°è¯•ä½¿ç”¨æ”¯æŒå¤æƒçš„æ•°æ®ç®¡ç†å™¨
            try:
                from data_manager.local_data_manager_with_adjustment import LocalDataManager as LocalDataManagerWithAdjustment
                manager_adjust = LocalDataManagerWithAdjustment()
                df = manager_adjust.load_data(stock_code, 'daily', adjust=adjust)
                manager_adjust.close()

                if not df.empty:
                    df = self._standardize_columns(df)
                    df = self._clean_data(df)
                    print(f"[OK] æœ¬åœ°ç¼“å­˜è·å– {len(df)} æ¡æ•°æ®ï¼ˆå¤æƒç±»å‹: {adjust}ï¼‰")
                    return df
                else:
                    return pd.DataFrame()

            except Exception:
                # å›é€€åˆ°åŸå§‹æ–¹æ³•
                local_results = self.local_data_manager.storage.load_batch(
                    [stock_code], 'daily', start_date, end_date
                )

                if stock_code in local_results:
                    df = local_results[stock_code]
                    df = self._standardize_columns(df)
                    df = self._clean_data(df)
                    print(f"[OK] æœ¬åœ°ç¼“å­˜è·å– {len(df)} æ¡æ•°æ®ï¼ˆæ— å¤æƒï¼‰")
                    return df

            return pd.DataFrame()

        except Exception as e:
            print(f"[WARNING] æœ¬åœ°ç¼“å­˜è·å–å¤±è´¥: {e}")
            return pd.DataFrame()

    def _get_qmt_data(self, stock_code: str, start_date: str, end_date: str, period: str, adjust: str = 'none') -> pd.DataFrame:
        """é€šè¿‡QMTè·å–çœŸå®æ•°æ®ï¼ˆæ”¯æŒå¤æƒï¼‰"""
        try:
            import xtquant.xtdata as xt_data
            
            # è½¬æ¢æ—¥æœŸæ ¼å¼
            start_time = datetime.strptime(start_date, '%Y-%m-%d').strftime('%Y%m%d')
            end_time = datetime.strptime(end_date, '%Y-%m-%d').strftime('%Y%m%d')
            
            # æ˜ å°„å¤æƒç±»å‹
            dividend_map = {
                'none': 'none',
                'front': 'front',
                'back': 'back'
            }
            dividend_type = dividend_map.get(adjust, 'none')

            # è·å–å†å²æ•°æ®ï¼ˆæ”¯æŒå¤æƒï¼‰
            data = xt_data.get_market_data_ex(
                stock_list=[stock_code],
                period=period,
                start_time=start_time,
                end_time=end_time,
                dividend_type=dividend_type,  # â† æ·»åŠ å¤æƒå‚æ•°
                fill_data=True
            )
            
            if data and stock_code in data:
                df = data[stock_code]
                
                # æ ‡å‡†åŒ–åˆ—å
                df = self._standardize_columns(df)
                
                # æ•°æ®æ¸…æ´—
                df = self._clean_data(df)
                
                print(f"[OK] QMTè·å– {len(df)} æ¡æ•°æ®")
                return df
            else:
                return pd.DataFrame()
                
        except Exception as e:
            print(f"[WARNING] QMTè·å–æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def _get_qstock_data(self, stock_code: str, start_date: str, end_date: str, period: str) -> pd.DataFrame:
        """é€šè¿‡QStockè·å–æ•°æ®"""
        try:
            import qstock as qs
            
            # è½¬æ¢è‚¡ç¥¨ä»£ç æ ¼å¼ (å»æ‰åç¼€)
            code = stock_code.split('.')[0]
            
            # è·å–æ•°æ®
            data = qs.get_data(code, start=start_date, end=end_date)
            
            if data is not None and not data.empty:
                # QStockè¿”å›çš„æ•°æ®æ ¼å¼é€šå¸¸æ˜¯æ ‡å‡†çš„OHLCVæ ¼å¼
                df = data.copy()
                
                # æ ‡å‡†åŒ–åˆ—å
                df = self._standardize_columns(df)
                
                # æ•°æ®æ¸…æ´—
                df = self._clean_data(df)
                
                print(f"[OK] QStockè·å– {len(df)} æ¡æ•°æ®")
                return df
            else:
                return pd.DataFrame()
                
        except Exception as e:
            print(f"[WARNING] QStockè·å–æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def _get_akshare_data(self, stock_code: str, start_date: str, end_date: str, period: str) -> pd.DataFrame:
        """é€šè¿‡AKShareè·å–æ•°æ® - å¢å¼ºé”™è¯¯å¤„ç†ç‰ˆæœ¬"""
        import time
        
        try:
            import akshare as ak
            
            # è½¬æ¢è‚¡ç¥¨ä»£ç æ ¼å¼
            code = stock_code.split('.')[0]
            
            # æ ¹æ®ä»£ç åç¼€ç¡®å®šå¸‚åœº
            if stock_code.endswith('.SZ'):
                symbol = code
            elif stock_code.endswith('.SH'):
                symbol = code
            else:
                symbol = code
            
            print(f"[RELOAD] å°è¯•é€šè¿‡AKShareè·å– {stock_code} æ•°æ®...")
            
            # é‡è¯•æœºåˆ¶ï¼šæœ€å¤šå°è¯•3æ¬¡
            max_retries = 3
            retry_delay = 2  # ç§’
            
            for attempt in range(max_retries):
                try:
                    # è·å–å†å²æ•°æ®
                    data = ak.stock_zh_a_hist(
                        symbol=symbol,
                        period="daily",
                        start_date=start_date.replace('-', ''),
                        end_date=end_date.replace('-', ''),
                        adjust="qfq"  # å‰å¤æƒ
                    )
                    
                    if data is not None and not data.empty:
                        # AKShareè¿”å›çš„åˆ—åé€šå¸¸æ˜¯ä¸­æ–‡ï¼Œéœ€è¦è½¬æ¢
                        column_mapping = {
                            'æ—¥æœŸ': 'date',
                            'å¼€ç›˜': 'open',
                            'æ”¶ç›˜': 'close', 
                            'æœ€é«˜': 'high',
                            'æœ€ä½': 'low',
                            'æˆäº¤é‡': 'volume',
                            'æˆäº¤é¢': 'amount',
                            'æŒ¯å¹…': 'amplitude',
                            'æ¶¨è·Œå¹…': 'pct_change',
                            'æ¶¨è·Œé¢': 'change',
                            'æ¢æ‰‹ç‡': 'turnover'
                        }
                        
                        df = data.rename(columns=column_mapping)
                        
                        # è®¾ç½®æ—¥æœŸç´¢å¼•
                        if 'date' in df.columns:
                            df['date'] = pd.to_datetime(df['date'])
                            df.set_index('date', inplace=True)
                        
                        # æ ‡å‡†åŒ–åˆ—å
                        df = self._standardize_columns(df)
                        
                        # æ•°æ®æ¸…æ´—
                        df = self._clean_data(df)
                        
                        print(f"[OK] AKShareè·å– {len(df)} æ¡æ•°æ® (å°è¯• {attempt + 1}/{max_retries})")
                        return df
                    else:
                        print(f"[WARNING] AKShareè¿”å›ç©ºæ•°æ® (å°è¯• {attempt + 1}/{max_retries})")
                        
                except Exception as retry_e:
                    print(f"[WARNING] AKShareè·å–å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {str(retry_e)}")
                    
                    # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…åé‡è¯•
                    if attempt < max_retries - 1:
                        print(f"[WAIT] ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                        time.sleep(retry_delay)
                        retry_delay *= 2  # æŒ‡æ•°é€€é¿
                    else:
                        # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œè®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯
                        error_msg = str(retry_e)
                        if "Server disconnected" in error_msg:
                            print("[INFO] æç¤ºï¼šAKShareæœåŠ¡å™¨è¿æ¥é—®é¢˜ï¼Œå¯èƒ½æ˜¯ç½‘ç»œä¸ç¨³å®šæˆ–æœåŠ¡å™¨ç»´æŠ¤")
                        elif "timeout" in error_msg.lower():
                            print("[INFO] æç¤ºï¼šè¯·æ±‚è¶…æ—¶ï¼Œå»ºè®®æ£€æŸ¥ç½‘ç»œè¿æ¥")
                        elif "403" in error_msg or "forbidden" in error_msg.lower():
                            print("[INFO] æç¤ºï¼šè®¿é—®è¢«æ‹’ç»ï¼Œå¯èƒ½è§¦å‘äº†åçˆ¬è™«æœºåˆ¶")
                        else:
                            print(f"[INFO] æç¤ºï¼šAKShareæ•°æ®è·å–å¤±è´¥ï¼Œé”™è¯¯è¯¦æƒ…ï¼š{error_msg}")
            
            # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
            print(f"[ERROR] AKShareè·å– {stock_code} æ•°æ®å¤±è´¥ï¼Œå·²å°è¯• {max_retries} æ¬¡")
            return pd.DataFrame()
                
        except ImportError:
            print("[WARNING] akshareæ¨¡å—æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install akshare")
            return pd.DataFrame()
        except Exception as e:
            print(f"[ERROR] AKShareæ¨¡å—åŠ è½½å¤±è´¥: {str(e)}")
            return pd.DataFrame()
    
    def _generate_mock_data(self, stock_code: str, start_date: str, end_date: str) -> pd.DataFrame:
        """ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®"""
        print(f"[INFO] ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®: {stock_code}")
        
        # åˆ›å»ºæ—¥æœŸèŒƒå›´
        dates = pd.date_range(start=start_date, end=end_date, freq='D')
        dates = dates[dates.weekday < 5]  # åªä¿ç•™å·¥ä½œæ—¥
        
        # ç”Ÿæˆä»·æ ¼æ•°æ®
        np.random.seed(hash(stock_code) % 2**32)  # åŸºäºè‚¡ç¥¨ä»£ç çš„å›ºå®šç§å­
        
        # åŸºç¡€ä»·æ ¼
        base_price = 10.0 + (hash(stock_code) % 100)
        
        # ç”Ÿæˆæ”¶ç›˜ä»·ï¼ˆéšæœºæ¸¸èµ°ï¼‰
        returns = np.random.normal(0.001, 0.02, len(dates))  # æ—¥æ”¶ç›Šç‡
        close_prices = [base_price]
        
        for ret in returns[1:]:
            new_price = close_prices[-1] * (1 + ret)
            close_prices.append(max(new_price, 0.1))  # é˜²æ­¢ä»·æ ¼ä¸ºè´Ÿ
        
        close_prices = np.array(close_prices)
        
        # ç”Ÿæˆå…¶ä»–ä»·æ ¼æ•°æ®
        high_prices = close_prices * (1 + np.abs(np.random.normal(0, 0.01, len(dates))))
        low_prices = close_prices * (1 - np.abs(np.random.normal(0, 0.01, len(dates))))
        
        # å¼€ç›˜ä»·åŸºäºå‰ä¸€æ—¥æ”¶ç›˜ä»·
        open_prices = np.roll(close_prices, 1)
        open_prices[0] = base_price
        open_prices = open_prices * (1 + np.random.normal(0, 0.005, len(dates)))
        
        # ç¡®ä¿ä»·æ ¼å…³ç³»åˆç† (low <= open,close <= high)
        for i in range(len(dates)):
            low_prices[i] = min(low_prices[i], open_prices[i], close_prices[i])
            high_prices[i] = max(high_prices[i], open_prices[i], close_prices[i])
        
        # ç”Ÿæˆæˆäº¤é‡
        volumes = np.random.lognormal(10, 1, len(dates)).astype(int) * 100
        
        # åˆ›å»ºDataFrame
        df = pd.DataFrame({
            'open': open_prices,
            'high': high_prices,
            'low': low_prices,
            'close': close_prices,
            'volume': volumes
        }, index=dates)
        
        print(f"[OK] ç”Ÿæˆ {len(df)} æ¡æ¨¡æ‹Ÿæ•°æ®")
        return df
    
    def _standardize_columns(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ ‡å‡†åŒ–åˆ—å"""
        column_mapping = {
            'Open': 'open',
            'High': 'high', 
            'Low': 'low',
            'Close': 'close',
            'Volume': 'volume',
            'Adj Close': 'adj_close'
        }
        
        # é‡å‘½ååˆ—
        df = df.rename(columns=column_mapping)
        
        # ç¡®ä¿å¿…è¦åˆ—å­˜åœ¨
        required_columns = ['open', 'high', 'low', 'close', 'volume']
        for col in required_columns:
            if col not in df.columns:
                if col == 'volume':
                    df[col] = 0
                else:
                    # å¦‚æœç¼ºå°‘ä»·æ ¼åˆ—ï¼Œç”¨closeä»·æ ¼å¡«å……
                    df[col] = df.get('close', 0)
        
        return df
    
    def _clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ•°æ®æ¸…æ´—"""
        print("[WIZARD] å¼€å§‹æ•°æ®æ¸…æ´—...")
        
        original_length = len(df)
        
        # 1. åˆ é™¤ç©ºå€¼
        df = df.dropna()
        
        # 2. åˆ é™¤ä»·æ ¼ä¸º0æˆ–è´Ÿæ•°çš„æ•°æ®
        price_columns = ['open', 'high', 'low', 'close']
        for col in price_columns:
            if col in df.columns:
                df = df[df[col] > 0]
        
        # 3. æ£€æŸ¥ä»·æ ¼å…³ç³»çš„åˆç†æ€§
        if all(col in df.columns for col in price_columns):
            # high >= max(open, close) and low <= min(open, close)
            valid_mask = (
                (df['high'] >= df[['open', 'close']].max(axis=1)) &
                (df['low'] <= df[['open', 'close']].min(axis=1))
            )
            df = df[valid_mask]
        
        # 4. åˆ é™¤å¼‚å¸¸æ³¢åŠ¨çš„æ•°æ®ï¼ˆæ—¥æ¶¨è·Œå¹…è¶…è¿‡20%ï¼‰
        if 'close' in df.columns and len(df) > 1:
            returns = df['close'].pct_change()
            normal_mask = (returns.abs() <= 0.2) | returns.isna()
            df = df[normal_mask]
        
        # 5. ç¡®ä¿æˆäº¤é‡ä¸ºæ­£æ•°
        if 'volume' in df.columns:
            df = df[df['volume'] >= 0]
        
        cleaned_length = len(df)
        removed_count = original_length - cleaned_length
        
        if removed_count > 0:
            print(f"[WIZARD] æ•°æ®æ¸…æ´—å®Œæˆï¼Œåˆ é™¤ {removed_count} æ¡å¼‚å¸¸æ•°æ®")
        
        return df
    
    def get_multiple_stocks_data(self, 
                               stock_codes: List[str], 
                               start_date: str, 
                               end_date: str) -> Dict[str, pd.DataFrame]:
        """
        è·å–å¤šåªè‚¡ç¥¨çš„æ•°æ®
        
        Args:
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            è‚¡ç¥¨ä»£ç åˆ°DataFrameçš„å­—å…¸
        """
        print(f"[DATA] æ‰¹é‡è·å– {len(stock_codes)} åªè‚¡ç¥¨æ•°æ®...")
        
        results = {}
        for stock_code in stock_codes:
            try:
                data = self.get_stock_data(stock_code, start_date, end_date)
                if not data.empty:
                    results[stock_code] = data
                else:
                    print(f"[WARNING] {stock_code} æ•°æ®ä¸ºç©º")
            except Exception as e:
                print(f"[WARNING] è·å– {stock_code} æ•°æ®å¤±è´¥: {e}")
        
        print(f"[OK] æˆåŠŸè·å– {len(results)} åªè‚¡ç¥¨æ•°æ®")
        return results
    
    def validate_data_quality(self, df: pd.DataFrame) -> Dict[str, any]:
        """
        éªŒè¯æ•°æ®è´¨é‡
        
        Args:
            df: å¾…éªŒè¯çš„æ•°æ®
            
        Returns:
            æ•°æ®è´¨é‡æŠ¥å‘Š
        """
        report = {
            'total_records': len(df),
            'date_range': {
                'start': self._safe_format_date(df.index.min() if not df.empty else None),
                'end': self._safe_format_date(df.index.max() if not df.empty else None)
            },
            'missing_values': df.isnull().sum().to_dict(),
            'data_completeness': (1 - df.isnull().sum() / len(df)).to_dict() if not df.empty else {},
            'price_statistics': {},
            'issues': []
        }
        
        if df.empty:
            report['issues'].append('æ•°æ®ä¸ºç©º')
            return report
        
        # ä»·æ ¼ç»Ÿè®¡
        price_columns = ['open', 'high', 'low', 'close']
        for col in price_columns:
            if col in df.columns:
                report['price_statistics'][col] = {
                    'min': float(df[col].min()),
                    'max': float(df[col].max()),
                    'mean': float(df[col].mean()),
                    'std': float(df[col].std())
                }
        
        # æ£€æŸ¥æ•°æ®é—®é¢˜
        if df.isnull().any().any():
            report['issues'].append('å­˜åœ¨ç¼ºå¤±å€¼')
        
        if 'close' in df.columns:
            returns = df['close'].pct_change().dropna()
            if (returns.abs() > 0.2).any():
                report['issues'].append('å­˜åœ¨å¼‚å¸¸æ³¢åŠ¨ï¼ˆå•æ—¥æ¶¨è·Œå¹…>20%ï¼‰')
        
        # æ£€æŸ¥ä»·æ ¼å…³ç³»
        if all(col in df.columns for col in price_columns):
            invalid_high = (df['high'] < df[['open', 'close']].max(axis=1)).any()
            invalid_low = (df['low'] > df[['open', 'close']].min(axis=1)).any()
            
            if invalid_high or invalid_low:
                report['issues'].append('å­˜åœ¨ä¸åˆç†çš„ä»·æ ¼å…³ç³»')
        
        return report
    
    def resample_data(self, df: pd.DataFrame, freq: str) -> pd.DataFrame:
        """
        é‡é‡‡æ ·æ•°æ®åˆ°ä¸åŒé¢‘ç‡
        
        Args:
            df: åŸå§‹æ•°æ®
            freq: ç›®æ ‡é¢‘ç‡ ('1H', '4H', '1D', '1W', '1M')
            
        Returns:
            é‡é‡‡æ ·åçš„æ•°æ®
        """
        if df.empty:
            return df
        
        # OHLCVæ•°æ®çš„é‡é‡‡æ ·è§„åˆ™
        agg_dict = {
            'open': 'first',
            'high': 'max',
            'low': 'min', 
            'close': 'last',
            'volume': 'sum'
        }
        
        # åªå¯¹å­˜åœ¨çš„åˆ—è¿›è¡Œé‡é‡‡æ ·
        available_agg = {k: v for k, v in agg_dict.items() if k in df.columns}
        
        resampled = df.resample(freq).agg(available_agg)
        
        # åˆ é™¤ç©ºå€¼è¡Œ
        resampled = resampled.dropna()
        
        print(f"[DATA] æ•°æ®é‡é‡‡æ ·å®Œæˆ: {len(df)} -> {len(resampled)} æ¡è®°å½• (é¢‘ç‡: {freq})")
        
        return resampled
    
    def _safe_format_date(self, date_obj) -> Optional[str]:
        """å®‰å…¨åœ°æ ¼å¼åŒ–æ—¥æœŸå¯¹è±¡"""
        if date_obj is None:
            return None
        
        try:
            # å¦‚æœæ˜¯pandas Timestampå¯¹è±¡
            if hasattr(date_obj, 'strftime'):
                return date_obj.strftime('%Y-%m-%d')
            # å¦‚æœæ˜¯datetimeå¯¹è±¡
            elif hasattr(date_obj, 'date'):
                return date_obj.date().strftime('%Y-%m-%d')
            # å°è¯•è½¬æ¢ä¸ºpandas Timestamp
            else:
                return pd.to_datetime(date_obj).strftime('%Y-%m-%d')
        except Exception as e:
            print(f"[WARNING] æ—¥æœŸæ ¼å¼åŒ–å¤±è´¥: {e}")
            return None

    # ========== æœ¬åœ°ç¼“å­˜ç®¡ç†æ–¹æ³• ==========

    def update_local_cache(self, symbols: List[str] = None, days_back: int = 5):
        """
        æ›´æ–°æœ¬åœ°ç¼“å­˜æ•°æ®

        Args:
            symbols: è¦æ›´æ–°çš„è‚¡ç¥¨åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºå…¨éƒ¨
            days_back: å‘å‰å›æº¯å¤©æ•°
        """
        if self.local_data_manager is None:
            print("[WARNING] æœ¬åœ°ç¼“å­˜æœªå¯ç”¨")
            return

        print("[RELOAD] æ›´æ–°æœ¬åœ°ç¼“å­˜...")
        self.local_data_manager.update_data(symbols=symbols)
        print("[OK] æ›´æ–°å®Œæˆ")

        # åˆ·æ–°æœ¬åœ°ç¼“å­˜çŠ¶æ€
        self.source_status[DataSource.LOCAL] = self._check_local_status()

    def get_local_cache_status(self) -> Dict[str, any]:
        """è·å–æœ¬åœ°ç¼“å­˜çŠ¶æ€"""
        if self.local_data_manager is None:
            return {'enabled': False}

        stats = self.local_data_manager.get_statistics()
        return {
            'enabled': True,
            'total_symbols': stats.get('total_symbols', 0),
            'total_records': stats.get('total_records', 0),
            'total_size_mb': stats.get('total_size_mb', 0),
            'latest_date': stats.get('latest_data_date', 'N/A')
        }

    def print_local_cache_status(self):
        """æ‰“å°æœ¬åœ°ç¼“å­˜çŠ¶æ€"""
        if self.local_data_manager is None:
            print("[WARNING] æœ¬åœ°ç¼“å­˜æœªå¯ç”¨")
            return

        print("\n" + "=" * 50)
        print("æœ¬åœ°ç¼“å­˜çŠ¶æ€")
        print("=" * 50)
        self.local_data_manager.print_summary()
        print("=" * 50 + "\n")

    def clear_local_cache(self, symbol: str = None):
        """
        æ¸…é™¤æœ¬åœ°ç¼“å­˜

        Args:
            symbol: è¦æ¸…é™¤çš„è‚¡ç¥¨ä»£ç ï¼ŒNoneè¡¨ç¤ºå…¨éƒ¨æ¸…é™¤
        """
        if self.local_data_manager is None:
            print("[WARNING] æœ¬åœ°ç¼“å­˜æœªå¯ç”¨")
            return

        # TODO: å®ç°æ¸…é™¤åŠŸèƒ½
        print(f"[WARNING] æ¸…é™¤æœ¬åœ°ç¼“å­˜åŠŸèƒ½å¾…å®ç°")

    def preload_data(self, symbols: List[str], start_date: str, end_date: str):
        """
        é¢„åŠ è½½æ•°æ®åˆ°æœ¬åœ°ç¼“å­˜

        Args:
            symbols: è‚¡ç¥¨åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
        """
        if self.local_data_manager is None:
            print("[WARNING] æœ¬åœ°ç¼“å­˜æœªå¯ç”¨")
            return

        print(f"ğŸ“¦ é¢„åŠ è½½ {len(symbols)} åªè‚¡ç¥¨æ•°æ®...")

        for symbol in symbols:
            try:
                # å°è¯•ä»å…¶ä»–æ•°æ®æºè·å–å¹¶ä¿å­˜
                data = self.get_stock_data(symbol, start_date, end_date, force_source=None)
                # get_stock_dataä¼šè‡ªåŠ¨ç¼“å­˜åˆ°æœ¬åœ°
            except Exception as e:
                print(f"[WARNING] é¢„åŠ è½½ {symbol} å¤±è´¥: {e}")

        print("[OK] é¢„åŠ è½½å®Œæˆ")


if __name__ == "__main__":
    # æµ‹è¯•æ•°æ®ç®¡ç†å™¨
    dm = DataManager()
    
    # æµ‹è¯•å•åªè‚¡ç¥¨æ•°æ®è·å–
    data = dm.get_stock_data('000001.SZ', '2023-01-01', '2023-12-31')
    print(f"[DATA] è·å–æ•°æ®å½¢çŠ¶: {data.shape}")
    print(f"[DATA] æ•°æ®åˆ—: {list(data.columns)}")
    
    # æµ‹è¯•æ•°æ®è´¨é‡éªŒè¯
    quality_report = dm.validate_data_quality(data)
    print(f"[DATA] æ•°æ®è´¨é‡æŠ¥å‘Š: {quality_report}")
    
    # æµ‹è¯•æ•°æ®é‡é‡‡æ ·
    weekly_data = dm.resample_data(data, '1W')
    print(f"[DATA] å‘¨çº¿æ•°æ®å½¢çŠ¶: {weekly_data.shape}")